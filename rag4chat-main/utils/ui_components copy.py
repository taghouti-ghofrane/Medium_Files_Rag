"""
UIç»„ä»¶æ¨¡å—ï¼ŒåŒ…å«æ‰€æœ‰Streamlit UIæ¸²æŸ“é€»è¾‘
"""
import streamlit as st
import pandas as pd
from datetime import datetime
from typing import Tuple, List, Any
import logging
from utils.document_processor import DocumentProcessor
from services.vector_store import VectorStoreService
from langchain_core.documents import Document
from config.settings import AVAILABLE_EMBEDDING_MODELS
import concurrent.futures
import functools
import asyncio

logger = logging.getLogger(__name__)

import streamlit as st
import base64
import re # ç”¨äºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å›¾ç‰‡è·¯å¾„

def convert_local_images_to_base64(markdown_text: str) -> str:
    """
    éå† Markdown æ–‡æœ¬ï¼ŒæŸ¥æ‰¾æœ¬åœ°å›¾ç‰‡è·¯å¾„ï¼Œå¹¶å°†å…¶æ›¿æ¢ä¸º Base64 åµŒç ã€‚
    æ³¨æ„ï¼šæ­¤å‡½æ•°å‡è®¾å›¾ç‰‡è·¯å¾„æ˜¯ Windows é£æ ¼çš„ç»å¯¹è·¯å¾„ã€‚
    """
    # å®šä¹‰ä¸€ä¸ªå†…éƒ¨å‡½æ•°æ¥å¤„ç†å›¾ç‰‡è½¬æ¢
    def _replace_image_path(match):
        alt_text = match.group(1) # è·å– alt text
        image_path = match.group(2) # è·å–å›¾ç‰‡è·¯å¾„
        
        # ç®€å•æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°è·¯å¾„ (å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´åˆ¤æ–­é€»è¾‘)
        # è¿™é‡Œå‡è®¾åŒ…å«ç›˜ç¬¦ï¼ˆå¦‚ D:\ï¼‰æˆ–ä»¥ \ æˆ– / å¼€å¤´çš„æ˜¯æœ¬åœ°è·¯å¾„
        if re.match(r'^[A-Za-z]:[\\\/]|^[\\\/]', image_path):
            try:
                # è¯»å–å›¾ç‰‡æ–‡ä»¶å¹¶è½¬æ¢ä¸º Base64
                with open(image_path, "rb") as img_file:
                    encoded_string = base64.b64encode(img_file.read()).decode('utf-8')
                
                # ç®€å•æ¨æ–­ MIME ç±»å‹ (å¯ä»¥æ ¹æ®æ–‡ä»¶æ‰©å±•åæ›´ç²¾ç¡®åœ°åˆ¤æ–­)
                # è¿™é‡Œåªå¤„ç†å¸¸è§çš„ JPEG å’Œ PNG
                mime_type = "image/jpeg"
                if image_path.lower().endswith(".png"):
                    mime_type = "image/png"
                elif image_path.lower().endswith(".gif"):
                    mime_type = "image/gif"
                # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šç±»å‹
                
                # è¿”å›æ–°çš„ Markdown å›¾ç‰‡æ ‡ç­¾ (ä½¿ç”¨ Base64)
                return f'![{alt_text}](data:{mime_type};base64,{encoded_string})'
            except FileNotFoundError:
                # å¦‚æœæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¿”å›åŸå§‹ Markdown æˆ–ä¸€ä¸ªé”™è¯¯æç¤º
                st.warning(f"å›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ— æ³•åµŒå…¥: {image_path}")
                return match.group(0) # è¿”å›åŸå§‹åŒ¹é…å†…å®¹
            except Exception as e:
                # å¤„ç†å…¶ä»–å¯èƒ½çš„é”™è¯¯ï¼ˆå¦‚è¯»å–æƒé™é—®é¢˜ï¼‰
                st.error(f"å¤„ç†å›¾ç‰‡ '{image_path}' æ—¶å‡ºé”™: {e}")
                return match.group(0) # è¿”å›åŸå§‹åŒ¹é…å†…å®¹
        else:
            # å¦‚æœä¸æ˜¯æœ¬åœ°è·¯å¾„ï¼ˆä¾‹å¦‚å·²ç»æ˜¯ URLï¼‰ï¼Œåˆ™ä¸ä¿®æ”¹
            return match.group(0)

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰ Markdown å›¾ç‰‡è¯­æ³• ![alt](path)
    # è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼ä¼šåŒ¹é… ![...](...) å¹¶æ•è· alt text å’Œ path
    pattern = r'!\[(.*?)\]\((.*?)\)'
    # ä½¿ç”¨ re.sub å’Œå›è°ƒå‡½æ•° _replace_image_path æ¥æ›¿æ¢åŒ¹é…é¡¹
    corrected_markdown_text = re.sub(pattern, _replace_image_path, markdown_text)
    
    return corrected_markdown_text

def run_async_in_thread(coro):
    """
    åœ¨ä¸€ä¸ªæ–°çº¿ç¨‹ä¸­è¿è¡Œåç¨‹ï¼Œå¹¶ç­‰å¾…å…¶å®Œæˆã€‚
    è¿™é¿å…äº†åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯ï¼ˆå¦‚ Streamlit çš„ï¼‰ä¸­ç›´æ¥æ“ä½œå¾ªç¯çš„é—®é¢˜ã€‚
    è¿”å›åç¨‹çš„ç»“æœæˆ–å¼•å‘å¼‚å¸¸ã€‚
    """
    def _run_in_thread():
        # åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºå¹¶è¿è¡Œä¸€ä¸ªæ–°çš„äº‹ä»¶å¾ªç¯
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            # åœ¨è¿™ä¸ªæ–°å¾ªç¯ä¸­è¿è¡Œåç¨‹ç›´åˆ°å®Œæˆ
            return loop.run_until_complete(coro)
        finally:
            # æ¸…ç†ï¼šå…³é—­æ–°åˆ›å»ºçš„å¾ªç¯
            loop.close()
            asyncio.set_event_loop(None) # é‡ç½®çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯

    # ä½¿ç”¨ ThreadPoolExecutor åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œ _run_in_thread å‡½æ•°
    with concurrent.futures.ThreadPoolExecutor() as executor:
        # æäº¤ä»»åŠ¡å¹¶ç­‰å¾…ç»“æœ
        future = executor.submit(_run_in_thread)
        # é˜»å¡ç­‰å¾…ç»“æœï¼ˆè¿™å‘ç”Ÿåœ¨ä¸»çº¿ç¨‹ï¼Œä½†ä¸ä¼šé˜»å¡ Streamlit çš„äº‹ä»¶å¾ªç¯å¤ªä¹…ï¼Œå› ä¸ºå·¥ä½œåœ¨åå°çº¿ç¨‹ï¼‰
        # å¦‚æœåç¨‹å†…éƒ¨æœ‰å¼‚å¸¸ï¼Œfuture.result() ä¼šé‡æ–°æŠ›å‡ºå®ƒ
        return future.result()
    
class UIComponents:
    """UIç»„ä»¶ç±»ï¼Œå°è£…äº†æ‰€æœ‰Streamlit UIæ¸²æŸ“é€»è¾‘"""
    
    # 1.æ¸²æŸ“æ¨¡å‹é€‰æ‹©ç»„ä»¶
    @staticmethod
    def render_model_selection(available_models: List[str], current_model: str, embedding_models: List[str], current_embedding_model: str) -> Tuple[str, str]:
        """
        available_models - å¯ç”¨æ¨¡å‹åˆ—è¡¨
        current_model - å½“å‰é€‰ä¸­çš„æ¨¡å‹
        embedding_models - å¯ç”¨åµŒå…¥æ¨¡å‹åˆ—è¡¨
        current_embedding_model - å½“å‰é€‰ä¸­çš„åµŒå…¥æ¨¡å‹

        @return (ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹, ç”¨æˆ·é€‰æ‹©çš„åµŒå…¥æ¨¡å‹)
        """
        st.sidebar.header("âš™ï¸ è®¾ç½®")
        
        new_model = st.sidebar.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=available_models,
            index=available_models.index(current_model) if current_model in available_models else 0,
            help="é€‰æ‹©è¦ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹"
        )
        
        new_embedding_model = st.sidebar.selectbox(
            "åµŒå…¥æ¨¡å‹",
            options=embedding_models,
            index=embedding_models.index(current_embedding_model) if current_embedding_model in embedding_models else 0,
            help="é€‰æ‹©ç”¨äºæ–‡æ¡£åµŒå…¥çš„æ¨¡å‹"
        )
        
        return new_model, new_embedding_model
    

    # 2. æ¸²æŸ“RAGè®¾ç½®ç»„ä»¶
    @staticmethod
    def render_rag_settings(rag_enabled: bool, similarity_threshold: float, default_threshold: float) -> Tuple[bool, float]:
        """
        rag_enabled - æ˜¯å¦å¯ç”¨RAG
        similarity_threshold - ç›¸ä¼¼åº¦é˜ˆå€¼
        default_threshold - é»˜è®¤ç›¸ä¼¼åº¦é˜ˆå€¼

        @return (æ˜¯å¦å¯ç”¨RAG, ç›¸ä¼¼åº¦é˜ˆå€¼)
        """
        st.sidebar.subheader("RAGè®¾ç½®")
        
        new_rag_enabled = st.sidebar.checkbox(
            "å¯ç”¨RAG",
            value=rag_enabled,
            help="å¯ç”¨æ£€ç´¢å¢å¼ºç”ŸæˆåŠŸèƒ½ï¼Œä½¿ç”¨ä¸Šä¼ çš„æ–‡æ¡£å¢å¼ºå›ç­”"
        )
        
        new_similarity_threshold = st.sidebar.slider(
            "ç›¸ä¼¼åº¦é˜ˆå€¼",
            min_value=0.0,
            max_value=1.0,
            value=similarity_threshold,
            step=0.05,
            help="è°ƒæ•´æ£€ç´¢ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå€¼è¶Šé«˜è¦æ±‚åŒ¹é…åº¦è¶Šç²¾ç¡®"
        )
        
        # å°†é‡ç½®ç›¸ä¼¼åº¦é˜ˆå€¼æŒ‰é’®æ ·å¼æ›´æ”¹ä¸ºå®¹å™¨å®½åº¦
        if st.sidebar.button("é‡ç½®ç›¸ä¼¼åº¦é˜ˆå€¼", use_container_width=True):
            new_similarity_threshold = default_threshold
            
        return new_rag_enabled, new_similarity_threshold
    

    # 3. æ¸²æŸ“èŠå¤©ç»Ÿè®¡ä¿¡æ¯
    @staticmethod
    def render_chat_stats(chat_history):
        """
        chat_history - èŠå¤©å†å²ç®¡ç†å™¨
        """
        st.sidebar.header("ğŸ’¬ å¯¹è¯å†å²")
        stats = chat_history.get_stats()
        st.sidebar.info(f"æ€»å¯¹è¯æ•°: {stats['total_messages']} ç”¨æˆ·æ¶ˆæ¯: {stats['user_messages']}")
        
        if st.sidebar.button("ğŸ“¥ å¯¼å‡ºå¯¹è¯å†å²", use_container_width=True):
            csv = chat_history.export_to_csv()
            if csv:
                st.sidebar.download_button(
                    label="ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv,
                    file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        from services.export_file import mdcontent2docx, mdcontent2pdf
        if st.sidebar.button("âœ… å¯¼å‡ºå½“å‰å†…å®¹ä¸ºPDF", use_container_width=True):
            # print(chat_history)
            last_assistant_message = None

            for message in chat_history.history:
                role = message.get('role', '') # å®‰å…¨åœ°è·å– 'role' é”®çš„å€¼
                content = message.get('content', '') # å®‰å…¨åœ°è·å– 'content' é”®çš„å€¼

                if role == 'assistant':
                    last_assistant_message = content # æ›´æ–°ä¸ºæœ€æ–°çš„ assistant æ¶ˆæ¯
            
            mdcontent2pdf(last_assistant_message, './now_content.pdf')
            st.rerun()

        if st.sidebar.button("ğŸš€ å¯¼å‡ºå½“å‰å†…å®¹ä¸ºDOCX", use_container_width=True):
            last_assistant_message = None

            for message in chat_history.history:
                role = message.get('role', '') # å®‰å…¨åœ°è·å– 'role' é”®çš„å€¼
                content = message.get('content', '') # å®‰å…¨åœ°è·å– 'content' é”®çš„å€¼

                if role == 'assistant':
                    last_assistant_message = content # æ›´æ–°ä¸ºæœ€æ–°çš„ assistant æ¶ˆæ¯
            mdcontent2docx(last_assistant_message, './now_content.docx')
            st.rerun()

        if st.sidebar.button("âœ¨ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            chat_history.clear_history()
            st.rerun()


    # 4. æ¸²æŸ“æ–‡æ¡£ä¸Šä¼ ç»„ä»¶
    @staticmethod
    def render_document_upload(
        document_processor: DocumentProcessor,
        vector_store: VectorStoreService,
        processed_documents: List[str]
    ) -> Tuple[List[Document], VectorStoreService]:
        """
        document_processor - æ–‡æ¡£å¤„ç†å™¨
        vector_store - å‘é‡å­˜å‚¨æœåŠ¡
        processed_documents - å·²å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨

        @return (all_docs, vector_store)
        """
        with st.expander("ğŸ“ ä¸Šä¼ ç”¨äºæ„å»ºçŸ¥è¯†åº“çš„åˆ†ææ–‡æ¡£", expanded=not bool(processed_documents)):
            uploaded_files = st.file_uploader(
                "ä¸Šä¼ PDFã€TXTã€DOCXã€MDæ–‡ä»¶", 
                type=["pdf", "txt", "docx", "md"],
                accept_multiple_files=True
            )
            
            if not vector_store.vector_store:
                st.warning("âš ï¸ è¯·åœ¨ä¾§è¾¹æ é…ç½®å‘é‡å­˜å‚¨ä»¥å¯ç”¨æ–‡æ¡£å¤„ç†ã€‚")
            
            all_docs = []
            if uploaded_files:
                if st.button("Process Documents"):
                    with st.spinner("æ­£åœ¨Process Documents..."):
                        for uploaded_file in uploaded_files:
                            if uploaded_file.name not in processed_documents:
                                try:
                                    # ç»Ÿä¸€å¤„ç†æ‰€æœ‰æ–‡ä»¶ç±»å‹
                                    result = document_processor.process_file(uploaded_file)
                                    
                                    if isinstance(result, list):
                                        # ç»“æœæ˜¯Documentåˆ—è¡¨(PDFæ–‡æ¡£)
                                        all_docs.extend(result)
                                    else:
                                        # ç»“æœæ˜¯æ–‡æœ¬å†…å®¹(TXTã€DOCXç­‰)
                                        doc = Document(
                                            page_content=result, 
                                            metadata={"source": uploaded_file.name}
                                        )
                                        all_docs.append(doc)
                                    
                                    processed_documents.append(uploaded_file.name)
                                    st.success(f"âœ… å·²å¤„ç†: {uploaded_file.name}")
                                except Exception as e:
                                    st.error(f"âŒ å¤„ç†å¤±è´¥: {uploaded_file.name} - {str(e)}")
                            else:
                                st.warning(f"âš ï¸ å·²å­˜åœ¨: {uploaded_file.name}")
                
                if all_docs:
                    document_paths = []
                    for doc in all_docs:
                        # --- å…³é”®ä¿®æ”¹ï¼šä» Document å¯¹è±¡ä¸­æå–è·¯å¾„ ---
                        # ä½ éœ€è¦æ ¹æ® Document å¯¹è±¡çš„å®é™…ç»“æ„æ¥è·å–è·¯å¾„
                        # å¸¸è§çš„æ˜¯åœ¨ metadata['source'] ä¸­
                        if hasattr(doc, 'metadata') and isinstance(doc.metadata, dict):
                            source_path = doc.metadata.get('source')
                            if source_path and isinstance(source_path, str):
                                document_paths.append(source_path)
                            else:
                                # å¤„ç†æ— æ³•è·å–è·¯å¾„çš„æƒ…å†µ
                                st.warning(f"âš ï¸ æ— æ³•ä»æ–‡æ¡£å¯¹è±¡è·å–æ–‡ä»¶è·¯å¾„: {doc}")
                                logger.warning(f"æ— æ³•ä»æ–‡æ¡£å¯¹è±¡è·å–æ–‡ä»¶è·¯å¾„: {doc}")
                        else:
                            # å¤„ç†æ²¡æœ‰ metadata æˆ– metadata ä¸æ˜¯å­—å…¸çš„æƒ…å†µ
                            st.warning(f"âš ï¸ æ–‡æ¡£å¯¹è±¡ç¼ºå°‘æœ‰æ•ˆçš„ metadata: {doc}")
                            logger.warning(f"æ–‡æ¡£å¯¹è±¡ç¼ºå°‘æœ‰æ•ˆçš„ metadata: {doc}")
                    # --- æ–°å¢ç»“æŸ ---
                    
                    if not document_paths:
                        st.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£è·¯å¾„å¯ä¾›å¤„ç†ã€‚")
                        logger.error("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£è·¯å¾„å¯ä¾›å¤„ç†ã€‚")
                        return # æˆ–å…¶ä»–é”™è¯¯å¤„ç†
                    with st.spinner("æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•..."):
                        import asyncio 
                        # vector_store.vector_store = vector_store.create_vector_store(all_docs)
                        # success = asyncio.run(vector_store.create_vector_store(document_paths))
                        # è·å–å½“å‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯
                        # loop = asyncio.get_event_loop()
                        # ä½¿ç”¨ run_until_complete åœ¨å½“å‰å¾ªç¯ä¸­ç­‰å¾…åç¨‹å®Œæˆ
                        success = run_async_in_thread(vector_store.create_vector_store(document_paths))
            
            # æ˜¾ç¤ºå·²Process Documentsåˆ—è¡¨
            if processed_documents:
                st.subheader("å·²Process Documents")
                for doc in processed_documents:
                    st.markdown(f"- {doc}")
                
                if st.button("æ¸…é™¤æ‰€æœ‰æ–‡æ¡£"):
                    with st.spinner("æ­£åœ¨æ¸…é™¤å‘é‡ç´¢å¼•..."):
                        vector_store.clear_index()
                        processed_documents.clear()
                    st.success("âœ… æ‰€æœ‰æ–‡æ¡£å·²æ¸…é™¤")
                    st.rerun()
            
            return all_docs, vector_store


    # 5. æ¸²æŸ“èŠå¤©å†å²
    @staticmethod
    def render_chat_history(chat_history):
        """
        chat_history - èŠå¤©å†å²ç®¡ç†å™¨
        """
        for message in chat_history.history:
            role = message.get('role', '')
            content = message.get('content', '')
            
            if role == "assistant_think":
                with st.expander("ğŸ’¡ æŸ¥çœ‹æ¨ç†è¿‡ç¨‹ <think> ... </think>"):
                    st.markdown(content)
            elif role == "retrieved_doc":
                with st.expander(f"ğŸ” æŸ¥çœ‹æœ¬æ¬¡å¬å›çš„æ–‡æ¡£å—", expanded=False):
                    if isinstance(content, list):
                        for idx, doc in enumerate(content, 1):
                            st.markdown(f"**æ–‡æ¡£å—{idx}:**\n{doc}")
                    else:
                        st.markdown(content)
            else:
                # with st.chat_message(role):
                #     st.write(content)
                print(content)
                corrected_markdown_content = convert_local_images_to_base64(content)

                # 2. æ¨é€åˆ°å‰ç«¯ (Streamlit èŠå¤©æ¡†)
                with st.chat_message("assistant"): 
                    st.markdown(corrected_markdown_content)

                original_markdown_content = """
                ### 3.2.2 å¤šé€šé“è¯­ä¹‰å›¾åƒ

                åœ¨ç›®æ ‡æ£€æµ‹ç®—æ³•FFTNetä¸­ï¼Œä¾¿é€šè¿‡ç°åº¦è¯­ä¹‰å›¾åƒæ„å»ºäº†é«˜æ–¯æ¤­åœ†ç»„æˆçš„Heatmapæ¥æŒ‡ç¤ºåƒç´ å±äºç›®æ ‡ä¸­å¿ƒç‚¹çš„æ¦‚ç‡ï¼Œä»¥åŠè¯¥ç›®æ ‡çš„å›å½’å°ºåº¦ã€‚

                #### 1. å›ºå®šéƒ¨ä»¶

                1.  åˆå§‹åŒ–ä¸€ä¸ªé•¿å®½ä¸º `width/8` å’Œ `height/8` çš„ç°åº¦å›¾åƒå¼ é‡ã€‚
                2.  éå†æ ‡å‡†å›¾æ ‡æ³¨ä¸­çš„æ¯ä¸€ä¸ªå›ºå®šéƒ¨ä»¶ï¼Œæ ¹æ®å…¶è¾¹ç•Œæ¡†ç”Ÿæˆç›®æ ‡çš„é«˜æ–¯æ¤­åœ†ã€‚
                3.  å°†æ¯ä¸ªå›ºå®šéƒ¨ä»¶çš„é«˜æ–¯æ¤­åœ†æ·»åŠ åœ¨å¯¹åº”ç±»åˆ«é€šé“çš„ç°åº¦è¯­ä¹‰å›¾åƒçš„å¯¹åº”ä½ç½®ä¸Šã€‚

                ![å›¾1ï¼šé«˜æ–¯æ¤­åœ†æ„é€ æ•ˆæœ](C:/Users/wcz13/Pictures/881.png)
                """

                # --- ä¿®æ­£å¹¶æ¨é€ ---
                # 1. ä¿®æ­£ Markdown å†…å®¹
                corrected_markdown_content = convert_local_images_to_base64(original_markdown_content)

                # 2. æ¨é€åˆ°å‰ç«¯ (Streamlit èŠå¤©æ¡†)
                with st.chat_message("assistant"): 
                    st.markdown(corrected_markdown_content)