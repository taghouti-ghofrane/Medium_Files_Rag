{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solar Cell Agentic RAG: Docling-to-RAG Pipeline Tutorial\n",
        "\n",
        "This notebook shows **end-to-end usage of the RAG pipeline based on the Docling parser**, reusing the project code.\n",
        "\n",
        "We will cover:\n",
        "- Ingestion with `DoclingProcessor` (Docling parsing + hybrid chunking)\n",
        "- Saving extracted chunks / tables / images to `data/processed`\n",
        "- Indexing into the vector store\n",
        "- Running queries through the high-level `RAGPipeline`\n",
        "\n",
        "> Run this notebook from the project root so that paths like `data/raw` and `src/...` resolve correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "\u001b[32m2025-12-18 11:31:12.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.graph\u001b[0m:\u001b[36mcreate_agent_graph\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mCreating agent graph...\u001b[0m\n",
            "\u001b[32m2025-12-18 11:31:12.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.graph\u001b[0m:\u001b[36mcreate_agent_graph\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mAgent graph compiled successfully\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded config processing settings:\n",
            "  enable_ocr: True\n",
            "  max_chunk_tokens: 256\n"
          ]
        }
      ],
      "source": [
        "# Ensure we can import the project modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Try to auto-detect the project root.\n",
        "# If you run the notebook from `notebooks/`, this will point one level up.\n",
        "cwd = Path.cwd()\n",
        "if (cwd / \"pyproject.toml\").exists():\n",
        "    project_root = cwd\n",
        "else:\n",
        "    project_root = cwd.parent\n",
        "\n",
        "# You can also hard-code it if needed, for example:\n",
        "# project_root = Path(r\"C:/Users/My Pc/Downloads/rag4chat-main/SAMI/solar-cell-agentic-rag\")\n",
        "\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(\"Project root:\", project_root)\n",
        "\n",
        "# Quick sanity check: can we import the pipeline?\n",
        "from src.rag_pipeline import RAGPipeline\n",
        "from src.ingestion.docling_processor import DoclingProcessor\n",
        "from configuration.config_loader import config\n",
        "\n",
        "print(\"Loaded config processing settings:\")\n",
        "print(\"  enable_ocr:\", config.processing.enable_ocr)\n",
        "print(\"  max_chunk_tokens:\", config.processing.max_chunk_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Select input PDF(s)\n",
        "\n",
        "We will work with PDF files from the `data/raw` directory.\n",
        "You can change `pdf_paths` to point to any other PDFs.\n",
        "\n",
        "The `DoclingProcessor` will:\n",
        "- Use Docling to **convert PDF → structured document**\n",
        "- Run the **HybridChunker** to create semantically meaningful text chunks\n",
        "- Extract **tables** and **images** with rich metadata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found PDFs in data/raw:\n",
            " - APC n° 2025-2251 du 14_11_2025.pdf\n",
            " - CELEX_62008CJ0059_SUM_EN_TXT.pdf\n",
            " - Test.pdf\n",
            " - TEST2.pdf\n",
            "\n",
            "Using these PDFs:\n",
            " - c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\raw\\APC n° 2025-2251 du 14_11_2025.pdf\n",
            " - c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\raw\\CELEX_62008CJ0059_SUM_EN_TXT.pdf\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[WindowsPath('c:/Users/My Pc/Downloads/rag4chat-main/SAMI/solar-cell-agentic-rag/data/raw/APC n° 2025-2251 du 14_11_2025.pdf'),\n",
              " WindowsPath('c:/Users/My Pc/Downloads/rag4chat-main/SAMI/solar-cell-agentic-rag/data/raw/CELEX_62008CJ0059_SUM_EN_TXT.pdf')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "raw_dir = project_root / \"data\" / \"raw\"\n",
        "pdf_paths = sorted(raw_dir.glob(\"*.pdf\"))\n",
        "\n",
        "print(\"Found PDFs in data/raw:\")\n",
        "for p in pdf_paths:\n",
        "    print(\" -\", p.name)\n",
        "\n",
        "# For the tutorial, pick one or a few PDFs\n",
        "selected_pdfs = pdf_paths[:2]\n",
        "print(\"\\nUsing these PDFs:\")\n",
        "for p in selected_pdfs:\n",
        "    print(\" -\", p)\n",
        "\n",
        "selected_pdfs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Process PDFs with `DoclingProcessor`\n",
        "\n",
        "This mirrors the logic in `src/ingestion/docling_processor.py`:\n",
        "- Configure Docling `PdfPipelineOptions` (OCR, table structure, images)\n",
        "- Convert each PDF to a Docling document object\n",
        "- Run `HybridChunker` to produce text chunks with metadata\n",
        "- Extract tables (`TableItem`) and images (`PictureItem`)\n",
        "\n",
        "We’ll wrap this into a simple loop over the selected PDFs and inspect the result structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-12-18 11:31:13.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mDoclingProcessor initialized (OCR: True, max_tokens: 256)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:31:13.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mProcessing document: APC n° 2025-2251 du 14_11_2025.pdf\u001b[0m\n",
            "2025-12-18 11:31:13,125 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing: APC n° 2025-2251 du 14_11_2025.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-18 11:31:13,386 - INFO - Going to convert document batch...\n",
            "2025-12-18 11:31:13,388 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 5e587a31a6093e580adab56a04d23dec\n",
            "2025-12-18 11:31:13,467 - INFO - Loading plugin 'docling_defaults'\n",
            "2025-12-18 11:31:13,471 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
            "2025-12-18 11:31:13,541 - INFO - Loading plugin 'docling_defaults'\n",
            "2025-12-18 11:31:13,555 - INFO - Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
            "2025-12-18 11:31:14,084 - INFO - Accelerator device: 'cpu'\n",
            "2025-12-18 11:31:18,417 - INFO - Accelerator device: 'cpu'\n",
            "2025-12-18 11:31:20,208 - INFO - Accelerator device: 'cpu'\n",
            "2025-12-18 11:31:21,738 - INFO - Processing document APC n° 2025-2251 du 14_11_2025.pdf\n",
            "c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "2025-12-18 11:34:08,390 - INFO - Finished converting document APC n° 2025-2251 du 14_11_2025.pdf in 175.27 sec.\n",
            "\u001b[32m2025-12-18 11:34:08.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mDocument converted: 4 pages\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:08.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mExtracted 0 tables\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:08.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mExtracted 2 images\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:08.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mCreated 8 text chunks\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:08.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mProcessing document: CELEX_62008CJ0059_SUM_EN_TXT.pdf\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  doc_id: APC n° 2025-2251 du 14_11_2025_0b1b375a\n",
            "  pages: 4\n",
            "  #chunks: 8\n",
            "  #tables: 0\n",
            "  #images: 2\n",
            "\n",
            "Processing: CELEX_62008CJ0059_SUM_EN_TXT.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-18 11:34:08,765 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
            "2025-12-18 11:34:08,803 - INFO - Going to convert document batch...\n",
            "2025-12-18 11:34:08,812 - INFO - Processing document CELEX_62008CJ0059_SUM_EN_TXT.pdf\n",
            "2025-12-18 11:34:21,473 - INFO - Finished converting document CELEX_62008CJ0059_SUM_EN_TXT.pdf in 12.94 sec.\n",
            "\u001b[32m2025-12-18 11:34:21.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mDocument converted: 4 pages\u001b[0m\n",
            "2025-12-18 11:34:21,477 - WARNING - Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
            "\u001b[32m2025-12-18 11:34:21.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mExtracted 1 tables\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:21.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mExtracted 0 images\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:21.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mCreated 8 text chunks\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  doc_id: CELEX_62008CJ0059_SUM_EN_TXT_10b172e9\n",
            "  pages: 4\n",
            "  #chunks: 8\n",
            "  #tables: 1\n",
            "  #images: 0\n",
            "\n",
            "Example chunk:\n",
            "{'chunk_id': 'APC n° 2025-2251 du 14_11_2025_0b1b375a_chunk_0',\n",
            " 'content': \"Considérant, par conséquent, qu'il y a lieu de réglementer les \"\n",
            "            'conditions délimination de ces composts ainsi que les conditions '\n",
            "            \"dentreposage dans l'attente de leur élimination finale ;\\n\"\n",
            "            'Sur proposition du Secrétaire Général de la préfecture de la '\n",
            "            'Meuse,',\n",
            " 'doc_id': 'APC n° 2025-2251 du 14_11_2025_0b1b375a',\n",
            " 'heading': None,\n",
            " 'page': 2,\n",
            " 'token_count': 38,\n",
            " 'type': 'text'}\n",
            "\n",
            "Example image:\n",
            "{'bbox': {'x0': 51.5792236328125,\n",
            "          'x1': 120.62897491455078,\n",
            "          'y0': 814.3222522735596,\n",
            "          'y1': 753.4652481079102},\n",
            " 'caption': None,\n",
            " 'doc_id': 'APC n° 2025-2251 du 14_11_2025_0b1b375a',\n",
            " 'image_id': 'APC n° 2025-2251 du 14_11_2025_0b1b375a_img1',\n",
            " 'page': 1}\n"
          ]
        }
      ],
      "source": [
        "processor = DoclingProcessor()\n",
        "\n",
        "processed_results = []\n",
        "for pdf_path in selected_pdfs:\n",
        "    print(\"\\nProcessing:\", pdf_path.name)\n",
        "    result = processor.process_document(pdf_path)\n",
        "    processed_results.append(result)\n",
        "    \n",
        "    print(\"  doc_id:\", result[\"doc_id\"])\n",
        "    print(\"  pages:\", result[\"pages\"])\n",
        "    print(\"  #chunks:\", len(result[\"chunks\"]))\n",
        "    print(\"  #tables:\", len(result[\"tables\"]))\n",
        "    print(\"  #images:\", len(result[\"images\"]))\n",
        "\n",
        "# Peek at one chunk / table / image metadata\n",
        "example = processed_results[0]\n",
        "print(\"\\nExample chunk:\")\n",
        "pprint(example[\"chunks\"][0])\n",
        "\n",
        "if example[\"tables\"]:\n",
        "    print(\"\\nExample table:\")\n",
        "    pprint(example[\"tables\"][0])\n",
        "\n",
        "if example[\"images\"]:\n",
        "    print(\"\\nExample image:\")\n",
        "    # We only print metadata, not raw image bytes\n",
        "    img_meta = {k: v for k, v in example[\"images\"][0].items() if k != \"image_data\"}\n",
        "    pprint(img_meta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Persist Docling outputs to `data/processed`\n",
        "\n",
        "The project expects processed artifacts in:\n",
        "- `data/processed/text` → JSON list of text chunks\n",
        "- `data/processed/tables` → JSON list of tables\n",
        "- `data/processed/images` → PNG image files + metadata JSON\n",
        "\n",
        "We will save the structures produced by `DoclingProcessor` in a format compatible with the existing indexing scripts (e.g. `scripts/index_processed_data.py`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved text chunks to c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\processed\\text\\APC n° 2025-2251 du 14_11_2025_0b1b375a_chunks.json\n",
            "Saved image metadata to c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\processed\\images\\APC n° 2025-2251 du 14_11_2025_0b1b375a_images_metadata.json\n",
            "Saved text chunks to c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\processed\\text\\CELEX_62008CJ0059_SUM_EN_TXT_10b172e9_chunks.json\n",
            "Saved tables to c:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\processed\\tables\\CELEX_62008CJ0059_SUM_EN_TXT_10b172e9_tables.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "processed_root = project_root / \"data\" / \"processed\"\n",
        "text_dir = processed_root / \"text\"\n",
        "tables_dir = processed_root / \"tables\"\n",
        "images_dir = processed_root / \"images\"\n",
        "\n",
        "for d in [text_dir, tables_dir, images_dir]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for doc in processed_results:\n",
        "    doc_id = doc[\"doc_id\"]\n",
        "    \n",
        "    # --- Save text chunks ---\n",
        "    text_path = text_dir / f\"{doc_id}_chunks.json\"\n",
        "    with text_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(doc[\"chunks\"], f, ensure_ascii=False, indent=2)\n",
        "    print(\"Saved text chunks to\", text_path)\n",
        "    \n",
        "    # --- Save tables ---\n",
        "    if doc[\"tables\"]:\n",
        "        tables_path = tables_dir / f\"{doc_id}_tables.json\"\n",
        "        # Optionally attach doc_id to each table\n",
        "        tables_with_doc = []\n",
        "        for t in doc[\"tables\"]:\n",
        "            t = dict(t)\n",
        "            t.setdefault(\"doc_id\", doc_id)\n",
        "            tables_with_doc.append(t)\n",
        "        with tables_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(tables_with_doc, f, ensure_ascii=False, indent=2)\n",
        "        print(\"Saved tables to\", tables_path)\n",
        "    \n",
        "    # --- Save images + metadata ---\n",
        "    if doc[\"images\"]:\n",
        "        images_meta = []\n",
        "        for img_info in doc[\"images\"]:\n",
        "            img_id = img_info[\"image_id\"]\n",
        "            pil_image = img_info[\"image_data\"]\n",
        "            img_file = images_dir / f\"{img_id}.png\"\n",
        "            \n",
        "            # Save the image\n",
        "            pil_image.save(img_file)\n",
        "            \n",
        "            # Prepare metadata record\n",
        "            meta = {\n",
        "                \"image_id\": img_id,\n",
        "                \"doc_id\": img_info[\"doc_id\"],\n",
        "                \"page\": img_info[\"page\"],\n",
        "                \"image_path\": str(img_file.relative_to(project_root)),\n",
        "                \"bbox\": img_info.get(\"bbox\"),\n",
        "                \"caption\": img_info.get(\"caption\"),\n",
        "            }\n",
        "            images_meta.append(meta)\n",
        "        \n",
        "        meta_path = images_dir / f\"{doc_id}_images_metadata.json\"\n",
        "        with meta_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(images_meta, f, ensure_ascii=False, indent=2)\n",
        "        print(\"Saved image metadata to\", meta_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Index processed data into the vector store\n",
        "\n",
        "At this point, `data/processed` contains the Docling-derived chunks, tables, and images.\n",
        "\n",
        "Instead of re-implementing the indexing logic, we use the high-level `RAGPipeline.index_processed_data`, which internally:\n",
        "- Loads JSON chunk/table/image files from `data/processed`\n",
        "- Uses `CLIPEmbedder` to embed text and images\n",
        "- Stores them in `VectorStore` (Chroma)\n",
        "\n",
        "This is similar to the behavior of `scripts/index_processed_data.py`, but callable from Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-12-18 11:34:21.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.rag_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mInitializing RAG Pipeline...\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:22.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.docling_processor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mDoclingProcessor initialized (OCR: True, max_tokens: 256)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:22.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.image_processor\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mImageProcessor initialized (output: C:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\processed\\images)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:22.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.ingestion.pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mIngestionPipeline initialized\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:22.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.embeddings.clip_embedder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mInitializing CLIP embedder: openai/clip-vit-base-patch32 on cpu\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:26.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.embeddings.clip_embedder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mCLIP model loaded successfully (device: cpu)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:26.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.vector_store\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mInitializing ChromaDB at C:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\vectordb\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.vector_store\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mVector store initialized: collection 'datasheet_collection' with 53 documents\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.unified_retriever\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mUnifiedRetriever initialized (top_k: 30)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.reranker\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mJinaReranker initialized (model: jina-colbert-v2, top_n: 15)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.rag_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mVector store has 53 documents\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.rag_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mRAG Pipeline initialized successfully\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.rag_pipeline\u001b[0m:\u001b[36mindex_processed_data\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mIndexing processed data... (Current: 53 docs)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.rag_pipeline\u001b[0m:\u001b[36mindex_processed_data\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mFound 5 unique documents already indexed\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.rag_pipeline\u001b[0m:\u001b[36mindex_processed_data\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1mIndexing complete: Added 0 text, 0 tables, 0 images. Vector store: 53 → 53 (+0)\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indexing processed data into the vector store...\n",
            "\n",
            "Indexed items:\n",
            "  text chunks: 0\n",
            "  tables: 0\n",
            "  images: 0\n",
            "\n",
            "Vector store statistics:\n",
            "  total_documents: 53\n",
            "  by_type: {'table': 8, 'image': 6, 'text': 39}\n"
          ]
        }
      ],
      "source": [
        "pipeline = RAGPipeline(auto_index=False)\n",
        "\n",
        "print(\"Indexing processed data into the vector store...\")\n",
        "index_counts = pipeline.index_processed_data()\n",
        "\n",
        "print(\"\\nIndexed items:\")\n",
        "print(\"  text chunks:\", index_counts.get(\"text\"))\n",
        "print(\"  tables:\", index_counts.get(\"tables\"))\n",
        "print(\"  images:\", index_counts.get(\"images\"))\n",
        "\n",
        "stats = pipeline.get_statistics()\n",
        "print(\"\\nVector store statistics:\")\n",
        "print(\"  total_documents:\", stats[\"total_documents\"]) \n",
        "print(\"  by_type:\", stats[\"by_type\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Ask questions with the RAG pipeline\n",
        "\n",
        "Now that the Docling-parsed and chunked content is indexed, we can issue natural language questions.\n",
        "\n",
        "Here we show two options:\n",
        "- **Direct `RAGPipeline.query`** → assumes data is already in the vector store\n",
        "- **`process_and_query`** → ingest + index + query in one call (handy for ad-hoc PDFs)\n",
        "\n",
        "We’ll start with `query` to reuse the data we just ingested.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-12-18 11:34:27.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.rag_pipeline\u001b[0m:\u001b[36mquery\u001b[0m:\u001b[36m297\u001b[0m - \u001b[1mProcessing query: 'What is the maximum power output?' (history: 0 messages)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36mretrieve_node\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1m[RETRIEVE NODE] Processing query: 'What is the maximum power output?'\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.tools\u001b[0m:\u001b[36msearch_knowledge_base\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mTool called: search_knowledge_base(query='What is the maximum power output?...', top_k=None)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.tools\u001b[0m:\u001b[36m_get_retriever\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mInitializing retrieval components for agent tool\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:27.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.embeddings.clip_embedder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mInitializing CLIP embedder: openai/clip-vit-base-patch32 on cpu\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is the maximum power output?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-12-18 11:34:30.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.embeddings.clip_embedder\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mCLIP model loaded successfully (device: cpu)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:30.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.vector_store\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mInitializing ChromaDB at C:\\Users\\My Pc\\Downloads\\rag4chat-main\\SAMI\\solar-cell-agentic-rag\\data\\vectordb\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:30.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.vector_store\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mVector store initialized: collection 'datasheet_collection' with 53 documents\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:30.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.unified_retriever\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mUnifiedRetriever initialized (top_k: 30)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:30.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.reranker\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mJinaReranker initialized (model: jina-colbert-v2, top_n: 15)\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:30.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.unified_retriever\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mRetrieving top-30 results for query: 'What is the maximum power output?...'\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:30.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.unified_retriever\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mRetrieved 30 results: 30 text/tables, 0 images\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:30.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.reranker\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mReranking 30 documents with Jina API\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.127\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36msrc.retrieval.reranker\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m111\u001b[0m - \u001b[31m\u001b[1mJina API error (status 401): {\"detail\":\"[RID: b1cd7a6d0659c9f95f610c92decee2a0] Invalid API key\"}\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.retrieval.reranker\u001b[0m:\u001b[36mrerank_results\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mReranked 30 results to top-15\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.tools\u001b[0m:\u001b[36msearch_knowledge_base\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mReranked 15 text chunks\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.tools\u001b[0m:\u001b[36msearch_knowledge_base\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mTool returning: 15 text chunks, 0 images\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36mretrieve_node\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1m[RETRIEVE NODE] Retrieved 15 chunks, 0 images in 3.44s\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36mshould_continue\u001b[0m:\u001b[36m241\u001b[0m - \u001b[1m[CONDITIONAL] Found 15 chunks, continuing to synthesis\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Generating answer for: 'What is the maximum power output?'\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Using 15 chunks, 0 images, 0 history messages\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:31.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Attempting moonshotai/kimi-k2-instruct-0905 (attempt 1/3)\u001b[0m\n",
            "2025-12-18 11:34:34,915 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
            "\u001b[32m2025-12-18 11:34:34.921\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m190\u001b[0m - \u001b[33m\u001b[1m[SYNTHESIZE NODE] Attempt 1 failed with moonshotai/kimi-k2-instruct-0905: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:35.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Attempting moonshotai/kimi-k2-instruct-0905 (attempt 2/3)\u001b[0m\n",
            "2025-12-18 11:34:35,962 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
            "\u001b[32m2025-12-18 11:34:35.963\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m190\u001b[0m - \u001b[33m\u001b[1m[SYNTHESIZE NODE] Attempt 2 failed with moonshotai/kimi-k2-instruct-0905: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:36.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Attempting moonshotai/kimi-k2-instruct-0905 (attempt 3/3)\u001b[0m\n",
            "2025-12-18 11:34:37,011 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
            "\u001b[32m2025-12-18 11:34:37.013\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m190\u001b[0m - \u001b[33m\u001b[1m[SYNTHESIZE NODE] Attempt 3 failed with moonshotai/kimi-k2-instruct-0905: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:37.015\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m192\u001b[0m - \u001b[31m\u001b[1m[SYNTHESIZE NODE] All retries exhausted for moonshotai/kimi-k2-instruct-0905\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:37.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Attempting openai/gpt-oss-120b (attempt 1/3)\u001b[0m\n",
            "2025-12-18 11:34:37,069 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
            "\u001b[32m2025-12-18 11:34:37.073\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m190\u001b[0m - \u001b[33m\u001b[1m[SYNTHESIZE NODE] Attempt 1 failed with openai/gpt-oss-120b: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:38.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Attempting openai/gpt-oss-120b (attempt 2/3)\u001b[0m\n",
            "2025-12-18 11:34:38,126 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
            "\u001b[32m2025-12-18 11:34:38.129\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m190\u001b[0m - \u001b[33m\u001b[1m[SYNTHESIZE NODE] Attempt 2 failed with openai/gpt-oss-120b: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:39.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Attempting openai/gpt-oss-120b (attempt 3/3)\u001b[0m\n",
            "2025-12-18 11:34:39,186 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
            "\u001b[32m2025-12-18 11:34:39.190\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m190\u001b[0m - \u001b[33m\u001b[1m[SYNTHESIZE NODE] Attempt 3 failed with openai/gpt-oss-120b: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:39.193\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m192\u001b[0m - \u001b[31m\u001b[1m[SYNTHESIZE NODE] All retries exhausted for openai/gpt-oss-120b\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:39.196\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m201\u001b[0m - \u001b[31m\u001b[1m[SYNTHESIZE NODE] All models and retries failed\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:39.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.agent.nodes\u001b[0m:\u001b[36msynthesize_node\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m[SYNTHESIZE NODE] Generated answer in 8.03s using fallback\u001b[0m\n",
            "\u001b[32m2025-12-18 11:34:39.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.rag_pipeline\u001b[0m:\u001b[36mquery\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mQuery complete: 15 chunks, 0 images\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Answer (truncated):\n",
            "I apologize, but I'm unable to generate an answer at this time due to technical difficulties. Please try again later.\n",
            "\n",
            "Metadata:\n",
            "  retrieval_time: 3.4383327960968018\n",
            "  num_chunks_retrieved: 15\n",
            "  num_images_retrieved: 0\n",
            "  retrieval_stats: {'total_retrieved': 30, 'text_chunks': 30, 'images': 0, 'avg_score': 0.7571517209211985, 'min_score': 0.7256559133529663, 'max_score': 0.7974576950073242}\n",
            "  synthesis_time: 8.031483888626099\n",
            "  model_used: fallback\n",
            "  confidence: low\n",
            "  sources_used: 0\n"
          ]
        }
      ],
      "source": [
        "question = \"What is the maximum power output?\"\n",
        "\n",
        "print(\"Question:\", question)\n",
        "\n",
        "result = pipeline.query(question)\n",
        "\n",
        "print(\"\\nAnswer (truncated):\")\n",
        "print(result[\"answer\"][:500])\n",
        "\n",
        "print(\"\\nMetadata:\")\n",
        "for k, v in result.get(\"metadata\", {}).items():\n",
        "    print(f\"  {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: One-shot `process_and_query`\n",
        "\n",
        "If you want to go **from raw PDFs directly to an answer in one call**, you can use `RAGPipeline.process_and_query`.\n",
        "\n",
        "This will internally:\n",
        "1. Use `DoclingProcessor` and the configured chunking strategy to process the PDFs\n",
        "2. Index the outputs\n",
        "3. Run a RAG query and return answer + metadata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: end-to-end in one call (commented out to avoid re-indexing every run)\n",
        "#\n",
        "# end_to_end_result = pipeline.process_and_query(\n",
        "#     pdf_paths=[str(p) for p in selected_pdfs],\n",
        "#     question=\"Summarize the main performance characteristics of this solar cell.\"\n",
        "# )\n",
        "#\n",
        "# print(\"Answer:\")\n",
        "# print(end_to_end_result[\"query\"][\"answer\"])\n",
        "#\n",
        "# print(\"\\nIngestion summary:\")\n",
        "# print(end_to_end_result[\"ingestion\"])\n",
        "#\n",
        "# print(\"\\nIndexing summary:\")\n",
        "# print(end_to_end_result[\"indexing\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Recap\n",
        "\n",
        "In this notebook we:\n",
        "- Used **`DoclingProcessor`** to parse PDFs and produce structured content (chunks, tables, images)\n",
        "- Persisted these artifacts under `data/processed` in a format expected by the project\n",
        "- Called **`RAGPipeline.index_processed_data`** to embed and store them in the vector store\n",
        "- Queried the system via **`RAGPipeline.query`** and (optionally) `process_and_query`\n",
        "\n",
        "You can now adapt this notebook to:\n",
        "- Point to your own PDFs in `data/raw`\n",
        "- Change chunking / OCR parameters in `configuration/config.yaml`\n",
        "- Experiment with different questions and evaluation scripts in `evaluation/`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
